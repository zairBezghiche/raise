# Module AI ‚Äî Intelligence Artificielle Neuro-Symbolique

Ce module impl√©mente l'approche **MBAIE** (Model-Based AI Engineering) de GenAptitude. Il transforme le langage naturel en structures d'ing√©nierie formelles, valides et persist√©es.

## üéØ Vision & Philosophie

L'IA de GenAptitude n'est pas un simple chatbot. C'est un **op√©rateur qualifi√©** qui agit sur le mod√®le.

1.  **Workstation-First** : Par d√©faut, l'intelligence tourne localement (Mistral via Docker).
2.  **Dual Mode** : Capacit√© √† d√©border sur le Cloud (Gemini Pro) pour les t√¢ches complexes n√©cessitant un raisonnement sup√©rieur.
3.  **Grounding (Ancrage)** : L'IA ne r√©pond jamais "dans le vide". Elle est nourrie par le contexte r√©el du projet (`json_db`) via un syst√®me RAG.
4.  **Int√©grit√©** : Les actions de l'IA passent par les m√™mes validateurs (`x_compute`, Schema Validator) que les actions humaines.

---

## üèóÔ∏è Architecture Modulaire

Le module est divis√© en trois sous-syst√®mes interconnect√©s. Chaque sous-syst√®me poss√®de sa propre documentation d√©taill√©e.

### 1\. [Le Cerveau Ex√©cutif (`agents/`)](https://www.google.com/search?q=./agents/README.md)

Responsable de la compr√©hension et de l'action.

- **Intent Classifier** : Analyse la demande (ex: "Cr√©e un acteur") et produit une structure Rust stricte.
- **Agents Sp√©cialis√©s** :
  - `SystemAgent` : Cr√©e/Modifie les √©l√©ments OA/SA (Acteurs, Fonctions).
  - _(Futur)_ `SoftwareAgent`, `HardwareAgent`.
- **Capacit√©s** : Enrichissement automatique des donn√©es (description g√©n√©r√©e) et insertion en base.

### 2\. [La M√©moire Contextuelle (`context/`)](https://www.google.com/search?q=./context/README.md)

Responsable de l'ancrage des r√©ponses dans la r√©alit√© du projet.

- **RAG Na√Øf (In-Memory)** : Le `SimpleRetriever` scanne le mod√®le charg√© en RAM pour trouver les √©l√©ments pertinents li√©s √† la question.
- **Injection** : Fournit au LLM un r√©sum√© textuel de l'existant ("Voici les acteurs actuels : ...").

### 3\. [L'Infrastructure d'Inf√©rence (`llm/`)](https://www.google.com/search?q=./llm/README.md)

Responsable de la communication brute avec les mod√®les.

- **Client Dual Mode** : Interface unifi√©e `ask()` qui route vers :
  - **Local** : `http://localhost:8080` (Docker/Mistral).
  - **Cloud** : Google Vertex AI (Gemini Pro).
- **Robustesse** : Gestion des timeouts, ping de sant√©, parsing JSON r√©silient.

---

## üîÑ Flux de Donn√©es (Orchestration)

L'orchestration est g√©r√©e par la commande `ai_chat` (dans `commands/ai_commands.rs`) ou par le CLI (`tools/ai_cli`).

```mermaid
graph TD
    User[Utilisateur] -->|Input| Orch[Orchestrateur (Command/CLI)]

    subgraph "Phase 1 : Compr√©hension"
        Orch -->|Classify| AG[Agents / Intent]
        AG -->|JSON Mode| LLM[LLM]
        LLM -->|Intent| AG
    end

    subgraph "Phase 2 : Contexte (Si Chat)"
        Orch -->|Load Model| DB[(JSON-DB)]
        DB --> CTX[Context / Retriever]
        CTX -->|Snippet| LLM
    end

    subgraph "Phase 3 : Action (Si Cr√©ation)"
        Orch -->|Process| AG
        AG -->|Generate Desc| LLM
        AG -->|Insert| DB
    end

    AG -->|R√©sultat| Orch
    Orch -->|R√©ponse| User
```

---

## üõ†Ô∏è Points d'Entr√©e

### 1\. Application GUI (Tauri)

L'utilisateur final interagit via le panneau de chat React.

- **Commande** : `ai_chat` (Async).
- **Retour** : Flux textuel ou confirmation d'action.

### 2\. Outil D√©veloppeur (`ai_cli`)

Pour le test rapide, l'automatisation et le d√©bogage sans interface graphique.

- **Localisation** : `src-tauri/tools/ai_cli`.
- **Commandes** :
  - `chat` : Discussion libre avec contexte.
  - `classify -x` : Test de la cha√Æne d'ex√©cution compl√®te (Cr√©ation DB).

---

## üìä √âtat d'Avancement (v0.1.0)

| Composant          | Statut     | Description                                         |
| :----------------- | :--------- | :-------------------------------------------------- |
| **LLM Client**     | ‚úÖ Stable  | Support Local/Cloud, Gestion d'erreurs.             |
| **Classification** | ‚úÖ Stable  | D√©tection pr√©cise (Create vs Chat), Nettoyage JSON. |
| **RAG**            | ‚ö†Ô∏è Basique | Recherche par mots-cl√©s sur mod√®le en m√©moire.      |
| **System Agent**   | ‚úÖ Actif   | Cr√©ation d'√©l√©ments OA/SA, Descriptions auto.       |
| **Software Agent** | ‚ùå Pr√©vu   | G√©n√©ration de code et composants logiques.          |
| **Vector DB**      | ‚ùå Pr√©vu   | Remplacement du RAG na√Øf par Qdrant/LEANN.          |

---

> **Note aux contributeurs :**
> Pour modifier la logique d'un agent, voir `src/ai/agents`.
> Pour changer de mod√®le LLM, modifier le `.env`.
> Pour toucher √† la base de donn√©es, passer par `json_db::collections::manager`.
