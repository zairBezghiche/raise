# ü§ñ Suite de Tests IA & Agents (`ai_suite`)

Ce module de test valide la couche d'intelligence artificielle de GenAptitude. Il s'assure que le syst√®me peut communiquer avec les LLMs (Locaux ou Cloud) et que les Agents autonomes (ex: `SystemAgent`) se comportent comme pr√©vu.

---

## üéØ Objectifs

Cette suite couvre deux aspects critiques :

1.  **Connectivit√© (LLM Client)** : V√©rifie que la plomberie technique (HTTP, Auth, Timeouts) vers les mod√®les d'IA fonctionne.
2.  **Comportement Agentique (Behavior)** : V√©rifie qu'un Agent comprend une intention (NLU) et effectue les actions concr√®tes sur le syst√®me de fichiers (JSON-DB).

---

## ‚öôÔ∏è Environnement de Test (`AiTestEnv`)

D√©fini dans `mod.rs`, cet environnement garantit l'isolation des tests.

- **Stockage Temporaire** : Utilise `tempfile` pour cr√©er une base de donn√©es JSON jetable.
- **Configuration Hybride** :
  - Charge les variables d'environnement (`.env`) pour les cl√©s API.
  - Configure un `StorageEngine` pointant vers le dossier temporaire.
- **Client LLM** : Pr√©-configur√© avec l'URL locale (`localhost:8080`) et la cl√© Gemini.

---

## üöÄ Ex√©cution des Tests

La suite distingue les tests de configuration (rapides) des tests d'inf√©rence (lents/externes).

### 1\. Tests de Configuration (Rapides)

V√©rifient uniquement que les cl√©s API sont pr√©sentes et que les structures s'instancient.

```bash
cargo test --test ai_suite
```

### 2\. Tests d'Int√©gration (N√©cessite LLM Local)

Ces tests effectuent de vrais appels r√©seaux vers le LLM. Ils sont marqu√©s `#[ignore]` pour ne pas bloquer la CI/CD standard.

**Pr√©requis :** Un serveur d'inf√©rence (Llama.cpp / Ollama) doit tourner sur le port 8080.

```bash
cargo test --test ai_suite -- --ignored
```

---

## üß™ Sc√©narios de Test

### 1\. Connectivit√© (`llm_tests.rs`)

- **`test_cloud_llm_config`** :
  - V√©rifie simplement la pr√©sence et la longueur de la cl√© API Gemini.
  - _Ne fait pas d'appel r√©seau._
- **`test_local_llm_connectivity`** (Ignored) :
  - Effectue un "Ping" s√©mantique.
  - Prompt : _"Tu es un test unitaire. R√©ponds juste 'PONG'."_
  - Validation : La r√©ponse ne doit pas √™tre vide.

### 2\. Agents & NLU (`agent_tests.rs`)

- **`test_intent_classification_integration`** (Ignored) :
  - Valide le `IntentClassifier`.
  - Input : _"Cr√©e une fonction syst√®me nomm√©e 'D√©marrer Moteur'"_.
  - Validation : V√©rifie que l'intention retourn√©e est bien `CreateElement`, couche `SA`, type `Function`.
- **`test_system_agent_creates_actor_end_to_end`** (Critique) :
  - Teste la cha√Æne compl√®te : **Intention -\> Agent -\> DB**.
  - Action : L'agent re√ßoit l'ordre de cr√©er un Acteur.
  - V√©rification : Le test va scanner physiquement le dossier temporaire `un2/_system/collections/actors` pour v√©rifier :
    1.  La pr√©sence du fichier JSON.
    2.  Que le contenu inclut une **description g√©n√©r√©e par l'IA** (preuve que le LLM a travaill√©).

---

## ‚ö†Ô∏è D√©pannage

**`SKIPPED: Serveur local introuvable`**

> Le client n'a pas r√©ussi √† joindre `http://localhost:8080/health`. V√©rifiez que votre conteneur Docker ou votre serveur Ollama est lanc√©.

**`Assertion failed: found` (dans `agent_tests`)**

> L'agent a bien tourn√©, mais le fichier n'a pas √©t√© trouv√© sur le disque.
>
> - V√©rifiez que l'agent √©crit bien dans l'espace `un2` (d√©faut).
> - V√©rifiez les logs pour voir si une erreur de validation JSON-Schema a emp√™ch√© l'√©criture.

**`Panic: Classification √©chou√©e`**

> Le LLM a "hallucin√©" et n'a pas respect√© le format de sortie JSON strict demand√© par le `IntentClassifier`. Relancez le test (le LLM est non-d√©terministe) ou ajustez le System Prompt.
